# ðŸ§­ Overview â€” What This Repo Does

This project is a **serverless backend** that automatically **creates interview reports** whenever a new interview event happens.

Itâ€™s part of a bigger system where one service sends messages (the _producer_), and this repo listens for them (the _consumer_).

When an interview is completed, a message gets dropped into a â€œmailboxâ€ on Azure called a **Service Bus Queue**.  
This consumer receives that message, looks up the interview details from a database (Supabase), processes the answers, calculates results, saves the report, and marks the job as complete.

In plain terms:

> The _producer_ says: â€œHey, interview X is done!â€  
> The _consumer_ says: â€œGot it. Iâ€™ll make a report for interview X now.â€

---

# ðŸ— How the Repo Is Structured

```
src/
 â”œâ”€â”€ index.ts
 â””â”€â”€ functions/
      â”œâ”€â”€ health/
      â”œâ”€â”€ oneWayReportConsumer/
      â”œâ”€â”€ codingInterviewReportConsumer/
      â”œâ”€â”€ RoleBasedInterviewReportConsumer/
      â”œâ”€â”€ softSkillInterviewReportConsumer/
      â””â”€â”€ technicalReportConsumer/
```

Each folder under `functions/` represents a **different task** the system can perform â€” each one is an independent â€œmini worker.â€  
All of them are loaded through `src/index.ts`.

---

# ðŸ“„ `src/index.ts` â€” The Entry Point

This file is like a **directory of workers**.  
It doesnâ€™t do any heavy lifting itself â€” it just _registers_ each worker (function) so that Azure knows what jobs exist.

In plain English:

> â€œHey Azure, here are all the workers you can call â€” one for one-way interview reports, one for coding interviews, one for technical interviews, and so on.â€

It also logs a message to confirm everything loaded correctly.

---

# ðŸ“„ `src/functions/oneWayReportConsumer/index.js` â€” The Worker

This is one of those workers â€” the **One Way Report Consumer**.  
Hereâ€™s the story of what it does:

1. **Waits for a message**
    
    - It listens to an Azure mailbox (Service Bus Queue).
        
    - When a new message arrives, Azure automatically wakes this function up.
        
2. **Reads what the message says**
    
    - The message usually looks like:  
        `{ "interviewId": "...", "eventId": "..." }`
        
    - It means â€œGenerate a report for this interview.â€
        
3. **Finds interview info**
    
    - It looks up which organization and candidate this interview belongs to in the database.
        
4. **Fetches data**
    
    - Gets all the questions that were asked.
        
    - Gets all the answers the candidate gave.
        
5. **Compares answers**
    
    - Checks which answers were correct.
        
    - Calculates how many were right/wrong.
        
    - Gives a score and a simple â€œrecommended / not recommendedâ€ verdict.
        
6. **Saves the report**
    
    - Writes all this information back into the database as a report record.
        
7. **Marks the job done**
    
    - Updates the original â€œeventâ€ as â€œcompletedâ€ or â€œfailed,â€ depending on success.
        
8. **Logs everything**
    
    - Throughout the process, it logs messages for debugging and tracking.
        

In short:

> â€œWhen an interview ends, Iâ€™ll grab the questions and answers, check how the candidate did, make a report, save it, and tell the system Iâ€™m done.â€

---

# ðŸ§  Big Picture of the Flow

1. The **Producer** finishes an interview â†’ sends a message (â€œInterview X doneâ€) to the queue.
    
2. The **Service Bus Queue** holds that message temporarily.
    
3. The **Consumer (this repo)** picks it up, processes it, and generates the report.
    
4. The **Database (Supabase)** stores all the interview data and reports.
    
5. The **System** marks that event as â€œcompleted.â€
    

So itâ€™s a simple message-driven workflow:

> Producer â†’ Azure Queue â†’ Consumer â†’ Database â†’ Status Updated